{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import googlemaps\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./newmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresdf = pickle.load(open('featuresextracted.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key='AIzaSyB8wxI-jE8QsQOasQPlfgORxPgfZcXAhXg')\n",
    "def getLocation():\n",
    "    nearest = []\n",
    "    result = []\n",
    "    options = Options()\n",
    "    options.add_argument(\"--use-fake-ui-for-media-stream\")\n",
    "    timeout = 20\n",
    "    driver = webdriver.Chrome(executable_path = './chromedriver.exe', options=options)\n",
    "    driver.get(\"https://mycurrentlocation.net/\")\n",
    "    wait = WebDriverWait(driver, timeout)\n",
    "    time.sleep(3)\n",
    "    longitude = driver.find_elements_by_xpath('//*[@id=\"longitude\"]')\n",
    "    longitude = [x.text for x in longitude]\n",
    "    longitude = longitude[0]\n",
    "    latitude = driver.find_elements_by_xpath('//*[@id=\"latitude\"]')\n",
    "    latitude = [x.text for x in latitude]\n",
    "    latitude = latitude[0]\n",
    "    driver.quit()\n",
    "    mapsFind = gmaps.find_place(input=[\"metro\"], input_type=\"textquery\", location_bias=\"point: {latitude}, {longitude}\".format(latitude=latitude, longitude=longitude))\n",
    "    result.append(mapsFind)\n",
    "    placeId = result[0]['candidates'][0]['place_id']\n",
    "    nearest_find = gmaps.place(place_id=placeId)\n",
    "    nearest.append(nearest_find)\n",
    "    return 'You are approaching your stop: ' + nearest[0]['result']['name'] + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "\n",
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_feature(file_name) \n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector)\n",
    "    print(predicted_class[0], '\\n') \n",
    "    \n",
    "    if predicted_class[0]== \"dingdong\":\n",
    "        print(getLocation())\n",
    "\n",
    "    predicted_proba_vector = model.predict(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        #print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dingdong \n",
      "\n",
      "You are approaching your stop: Santa Apol√≥nia.\n"
     ]
    }
   ],
   "source": [
    "# Test Sound\n",
    "filename = 'C:/Users/ivana/Desktop/fresh testing sounds/test 1.wav' \n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
